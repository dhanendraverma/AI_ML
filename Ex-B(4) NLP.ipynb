{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import SnowballStemmer\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import wordpunct_tokenize\n",
    "from nltk import stem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "stop_words.update(['.',',','?'])\n",
    "sno = SnowballStemmer('english')\n",
    "lemma = stem.WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stamming hello\n",
      "lemmatizing hello\n",
      "Stamming weather\n",
      "lemmatizing weather\n",
      "Stamming awesom\n",
      "lemmatizing awesome\n",
      "Stamming rain\n",
      "lemmatizing raining\n",
      "Stamming hello\n",
      "lemmatizing hello\n",
      "Stamming mr\n",
      "lemmatizing mr\n",
      "Stamming raja\n",
      "lemmatizing raja\n",
      "Stamming weather\n",
      "lemmatizing weather\n",
      "Stamming awesom\n",
      "lemmatizing awesome\n",
      "Stamming rain\n",
      "lemmatizing raining\n",
      "Stamming hello\n",
      "lemmatizing hello\n",
      "Stamming mr\n",
      "lemmatizing mr\n",
      "Stamming raja\n",
      "lemmatizing raja\n",
      "Stamming weather\n",
      "lemmatizing weather\n",
      "Stamming bad\n",
      "lemmatizing bad\n",
      "Stamming heavili\n",
      "lemmatizing heavily\n",
      "Stamming rain\n",
      "lemmatizing raining\n",
      "Stamming nlp\n",
      "lemmatizing nlp\n",
      "Stamming great\n",
      "lemmatizing great\n",
      "Stamming techniqu\n",
      "lemmatizing technique\n",
      "Stamming nice\n",
      "lemmatizing nice\n",
      "Stamming learn\n",
      "lemmatizing learn\n",
      "Stamming techniqu\n",
      "lemmatizing technique\n",
      "Stamming ai\n",
      "lemmatizing ai\n",
      "Stamming make\n",
      "lemmatizing making\n",
      "Stamming differ\n",
      "lemmatizing difference\n",
      "Stamming world\n",
      "lemmatizing world\n",
      "Stamming would\n",
      "lemmatizing would\n",
      "Stamming help\n",
      "lemmatizing helpful\n",
      "Stamming better\n",
      "lemmatizing betterment\n",
      "Stamming human\n",
      "lemmatizing human\n",
      "Stamming life\n",
      "lemmatizing life\n",
      "Stamming need\n",
      "lemmatizing need\n",
      "Stamming make\n",
      "lemmatizing make\n",
      "Stamming advantag\n",
      "lemmatizing advantage\n"
     ]
    }
   ],
   "source": [
    "for j in open(r'C:\\Users\\CG-DTE\\Downloads\\NLPdataEx3&4-data_in.txt'):\n",
    "    words=[i.lower() for i in wordpunct_tokenize(j) if i.lower() not in stop_words]\n",
    "    for k in words:\n",
    "        print(\"Stamming\",sno.stem(k))\n",
    "        print(\"lemmatizing\",lemma.lemmatize(k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
